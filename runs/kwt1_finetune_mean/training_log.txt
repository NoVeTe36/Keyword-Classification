Step: 0 | epoch: 0 | loss: 3.6828505992889404 | lr: 2.94117647050173e-06
Step: 20 | epoch: 0 | loss: 3.6037240028381348 | lr: 6.176470588053633e-05
Step: 34 | epoch: 0 | time_per_epoch: 10.344055891036987 | train_acc: 0.02976015086333903 | avg_loss_per_ep: 3.6281536046196434
Step: 34 | epoch: 0 | val_loss: 3.5714611530303957 | val_acc: 0.034265103697024346
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.034265103697024346.
Step: 40 | epoch: 1 | loss: 3.543663501739502 | lr: 0.00012058823529057094
Step: 60 | epoch: 1 | loss: 3.526411533355713 | lr: 0.00017941176470060553
Step: 68 | epoch: 1 | time_per_epoch: 9.829170942306519 | train_acc: 0.03966055748718251 | avg_loss_per_ep: 3.5340835907879997
Step: 80 | epoch: 2 | loss: 3.4935970306396484 | lr: 0.00023823529411064014
Step: 100 | epoch: 2 | loss: 3.5107626914978027 | lr: 0.0002970588235206748
Step: 102 | epoch: 2 | time_per_epoch: 7.3775904178619385 | train_acc: 0.0546879603983735 | avg_loss_per_ep: 3.503716931623571
Step: 120 | epoch: 3 | loss: 3.4963955879211426 | lr: 0.0003558823529307093
Step: 136 | epoch: 3 | time_per_epoch: 10.115836143493652 | train_acc: 0.06411691908774825 | avg_loss_per_ep: 3.4864928862627815
Step: 140 | epoch: 4 | loss: 3.4682528972625732 | lr: 0.000414705882340744
Step: 160 | epoch: 4 | loss: 3.412496566772461 | lr: 0.00047352941175077853
Step: 170 | epoch: 4 | time_per_epoch: 9.752948760986328 | train_acc: 0.08091225175319701 | avg_loss_per_ep: 3.4394149780273438
Step: 180 | epoch: 5 | loss: 3.3573312759399414 | lr: 0.0005323529411608132
Step: 200 | epoch: 5 | loss: 3.2255208492279053 | lr: 0.0005911764705708478
Step: 204 | epoch: 5 | time_per_epoch: 9.780417680740356 | train_acc: 0.1206906712239967 | avg_loss_per_ep: 3.3077132561627556
Step: 204 | epoch: 5 | val_loss: 3.124266481399536 | val_acc: 0.20529005109708445
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.20529005109708445.
Step: 220 | epoch: 6 | loss: 3.1460790634155273 | lr: 0.0006499999999808823
Step: 238 | epoch: 6 | time_per_epoch: 12.617269039154053 | train_acc: 0.17131239318757735 | avg_loss_per_ep: 3.0968580806956574
Step: 240 | epoch: 7 | loss: 2.9832515716552734 | lr: 0.0007088235293909169
Step: 260 | epoch: 7 | loss: 2.9017107486724854 | lr: 0.0007676470588009516
Step: 272 | epoch: 7 | time_per_epoch: 14.247569799423218 | train_acc: 0.24474040898108315 | avg_loss_per_ep: 2.863406538963318
Step: 280 | epoch: 8 | loss: 2.729755401611328 | lr: 0.0008264705882109863
Step: 300 | epoch: 8 | loss: 2.5537919998168945 | lr: 0.0008852941176210207
Step: 306 | epoch: 8 | time_per_epoch: 11.428498268127441 | train_acc: 0.3108020507985149 | avg_loss_per_ep: 2.6874237130669987
Step: 320 | epoch: 9 | loss: 2.536083698272705 | lr: 0.0009441176470310553
Step: 340 | epoch: 9 | time_per_epoch: 16.86898136138916 | train_acc: 0.359773704991455 | avg_loss_per_ep: 2.5438840669744156
Step: 340 | epoch: 10 | loss: 2.521919012069702 | lr: 0.0009999998736742225
Step: 360 | epoch: 10 | loss: 2.3849472999572754 | lr: 0.0009999443043049356
Step: 374 | epoch: 10 | time_per_epoch: 11.471447229385376 | train_acc: 0.4046791207496022 | avg_loss_per_ep: 2.4174253449720493
Step: 374 | epoch: 10 | val_loss: 1.9638879001140594 | val_acc: 0.5968339845706843
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.5968339845706843.
Step: 380 | epoch: 11 | loss: 2.3161120414733887 | lr: 0.0009997877107946946
Step: 400 | epoch: 11 | loss: 2.3423359394073486 | lr: 0.0009995301247867907
Step: 408 | epoch: 11 | time_per_epoch: 13.894094705581665 | train_acc: 0.4458718840238081 | avg_loss_per_ep: 2.3224837639752556
Step: 420 | epoch: 12 | loss: 2.284811496734619 | lr: 0.0009991715983323525
Step: 440 | epoch: 12 | loss: 2.297445774078369 | lr: 0.000998712203879829
Step: 442 | epoch: 12 | time_per_epoch: 11.748973608016968 | train_acc: 0.46443514644351463 | avg_loss_per_ep: 2.256498280693503
Step: 460 | epoch: 13 | loss: 2.247795581817627 | lr: 0.000998152034260349
Step: 476 | epoch: 13 | time_per_epoch: 16.313920497894287 | train_acc: 0.47427662207554955 | avg_loss_per_ep: 2.216206256081076
Step: 480 | epoch: 14 | loss: 2.3047094345092773 | lr: 0.0009974912026689635
Step: 500 | epoch: 14 | loss: 2.149444103240967 | lr: 0.000996729842641769
Step: 510 | epoch: 14 | time_per_epoch: 17.389984607696533 | train_acc: 0.4911898167246155 | avg_loss_per_ep: 2.188250120948343
Step: 520 | epoch: 15 | loss: 2.1024279594421387 | lr: 0.0009958681080289272
Step: 540 | epoch: 15 | loss: 2.1412131786346436 | lr: 0.000994906172963575
Step: 544 | epoch: 15 | time_per_epoch: 20.092729806900024 | train_acc: 0.49678826094643175 | avg_loss_per_ep: 2.1524691511602962
Step: 544 | epoch: 15 | val_loss: 1.6778967797756195 | val_acc: 0.6869051197274822
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.6869051197274822.
Step: 560 | epoch: 16 | loss: 2.098623752593994 | lr: 0.0009938442318266354
Step: 578 | epoch: 16 | time_per_epoch: 13.437541007995605 | train_acc: 0.5135835936118804 | avg_loss_per_ep: 2.115779014194713
Step: 580 | epoch: 17 | loss: 2.12831974029541 | lr: 0.0009926824992075398
Step: 600 | epoch: 17 | loss: 2.0935263633728027 | lr: 0.000991421209860865
Step: 612 | epoch: 17 | time_per_epoch: 10.503845930099487 | train_acc: 0.5242501031292357 | avg_loss_per_ep: 2.0807088333017685
Step: 620 | epoch: 18 | loss: 2.0893990993499756 | lr: 0.0009900606186588955
Step: 640 | epoch: 18 | loss: 2.1303911209106445 | lr: 0.0009886010005401217
Step: 646 | epoch: 18 | time_per_epoch: 11.988664150238037 | train_acc: 0.5264894808179622 | avg_loss_per_ep: 2.062687007819905
Step: 660 | epoch: 19 | loss: 1.9983025789260864 | lr: 0.0009870426504536814
Step: 680 | epoch: 19 | time_per_epoch: 16.750605583190918 | train_acc: 0.535034474630208 | avg_loss_per_ep: 2.0456304830663345
Step: 680 | epoch: 20 | loss: 2.078518867492676 | lr: 0.0009853858832997576
Step: 700 | epoch: 20 | loss: 1.9821221828460693 | lr: 0.0009836310338659474
Step: 714 | epoch: 20 | time_per_epoch: 16.17047119140625 | train_acc: 0.5354469915728681 | avg_loss_per_ep: 2.0432382225990295
Step: 714 | epoch: 20 | val_loss: 1.5718925416469574 | val_acc: 0.725278028253682
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.725278028253682.
Step: 720 | epoch: 21 | loss: 2.015744924545288 | lr: 0.0009817784567596106
Step: 740 | epoch: 21 | loss: 2.070984363555908 | lr: 0.0009798285263362132
Step: 748 | epoch: 21 | time_per_epoch: 17.018721342086792 | train_acc: 0.5498850845659733 | avg_loss_per_ep: 2.01927988318836
Step: 760 | epoch: 22 | loss: 1.9863135814666748 | lr: 0.0009777816366236777
Step: 780 | epoch: 22 | loss: 1.9483850002288818 | lr: 0.0009756382012427636
Step: 782 | epoch: 22 | time_per_epoch: 11.326847791671753 | train_acc: 0.5430490895161766 | avg_loss_per_ep: 2.00669359108981
Step: 800 | epoch: 23 | loss: 2.0756547451019287 | lr: 0.0009733986533234847
Step: 816 | epoch: 23 | time_per_epoch: 14.610997676849365 | train_acc: 0.5527137721727857 | avg_loss_per_ep: 1.9913926054449642
Step: 820 | epoch: 24 | loss: 2.08096981048584 | lr: 0.000971063445417587
Step: 840 | epoch: 24 | loss: 1.9509996175765991 | lr: 0.0009686330494070983
Step: 850 | epoch: 24 | time_per_epoch: 16.53280735015869 | train_acc: 0.5491189816724615 | avg_loss_per_ep: 1.9903837793013628
Step: 860 | epoch: 25 | loss: 1.9448742866516113 | lr: 0.0009661079564089737
Step: 880 | epoch: 25 | loss: 1.970654010772705 | lr: 0.0009634886766758558
Step: 884 | epoch: 25 | time_per_epoch: 7.132377624511719 | train_acc: 0.5573103895338558 | avg_loss_per_ep: 1.9747727723682629
Step: 884 | epoch: 25 | val_loss: 1.486437726020813 | val_acc: 0.7492235246969241
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.7492235246969241.
Step: 900 | epoch: 26 | loss: 1.9552757740020752 | lr: 0.0009607757394929652
Step: 918 | epoch: 26 | time_per_epoch: 16.492228031158447 | train_acc: 0.5709823796334492 | avg_loss_per_ep: 1.9399567737298853
Step: 920 | epoch: 27 | loss: 1.984591007232666 | lr: 0.0009579696930711469
Step: 940 | epoch: 27 | loss: 1.960825800895691 | lr: 0.0009550711044360908
Step: 952 | epoch: 27 | time_per_epoch: 9.26588749885559 | train_acc: 0.5711002416170664 | avg_loss_per_ep: 1.9406705603880041
Step: 960 | epoch: 28 | loss: 1.9300389289855957 | lr: 0.000952080559313753
Step: 980 | epoch: 28 | loss: 2.0078091621398926 | lr: 0.000948998662011995
Step: 986 | epoch: 28 | time_per_epoch: 16.175642013549805 | train_acc: 0.5774058577405857 | avg_loss_per_ep: 1.9040218311197616
Step: 1000 | epoch: 29 | loss: 1.886020541191101 | lr: 0.0009458260352984705
Step: 1020 | epoch: 29 | time_per_epoch: 10.82373332977295 | train_acc: 0.5837704048559137 | avg_loss_per_ep: 1.8978557446423698
Step: 1020 | epoch: 30 | loss: 1.8776168823242188 | lr: 0.00094256332027478
Step: 1040 | epoch: 30 | loss: 1.9212590456008911 | lr: 0.0009392111762469223
Step: 1054 | epoch: 30 | time_per_epoch: 14.806451559066772 | train_acc: 0.590370675938476 | avg_loss_per_ep: 1.8831556369276607
Step: 1054 | epoch: 30 | val_loss: 1.438491988182068 | val_acc: 0.761847510269512
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.761847510269512.
Step: 1060 | epoch: 31 | loss: 1.8315918445587158 | lr: 0.0009357702805920672
Step: 1080 | epoch: 31 | loss: 1.8580533266067505 | lr: 0.0009322413286216745
Step: 1088 | epoch: 31 | time_per_epoch: 13.0368070602417 | train_acc: 0.5895456420531557 | avg_loss_per_ep: 1.8838714957237244
Step: 1100 | epoch: 32 | loss: 1.8846594095230103 | lr: 0.0009286250334409911
Step: 1120 | epoch: 32 | loss: 1.8529365062713623 | lr: 0.0009249221258049536
Step: 1122 | epoch: 32 | time_per_epoch: 16.193923473358154 | train_acc: 0.5980906358654016 | avg_loss_per_ep: 1.8699317118700813
Step: 1140 | epoch: 33 | loss: 1.8308290243148804 | lr: 0.0009211333539705192
Step: 1156 | epoch: 33 | time_per_epoch: 9.166426420211792 | train_acc: 0.6016264953739171 | avg_loss_per_ep: 1.8388245070681852
Step: 1160 | epoch: 34 | loss: 1.7673076391220093 | lr: 0.0009172594835454655
Step: 1180 | epoch: 34 | loss: 1.8079617023468018 | lr: 0.0009133012973336823
Step: 1190 | epoch: 34 | time_per_epoch: 16.558303356170654 | train_acc: 0.6068713536448819 | avg_loss_per_ep: 1.8332587129929487
Step: 1200 | epoch: 35 | loss: 1.887252688407898 | lr: 0.0009092595951769865
Step: 1220 | epoch: 35 | loss: 1.7803988456726074 | lr: 0.000905135193793498
Step: 1224 | epoch: 35 | time_per_epoch: 11.416441202163696 | train_acc: 0.6128233838175496 | avg_loss_per_ep: 1.8343974492129158
Step: 1224 | epoch: 35 | val_loss: 1.3691721379756927 | val_acc: 0.7820859633303276
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.7820859633303276.
Step: 1240 | epoch: 36 | loss: 1.7654273509979248 | lr: 0.0009009289266126008
Step: 1258 | epoch: 36 | time_per_epoch: 11.702078580856323 | train_acc: 0.610466144145206 | avg_loss_per_ep: 1.8053378462791443
Step: 1260 | epoch: 37 | loss: 1.8386896848678589 | lr: 0.0008966416436065322
Step: 1280 | epoch: 37 | loss: 1.8789598941802979 | lr: 0.0008922742111186236
Step: 1292 | epoch: 37 | time_per_epoch: 16.183449745178223 | train_acc: 0.6079910424892451 | avg_loss_per_ep: 1.81590434032328
Step: 1300 | epoch: 38 | loss: 1.7789325714111328 | lr: 0.000887827511688238
Step: 1320 | epoch: 38 | loss: 1.859264612197876 | lr: 0.000883302443872433
Step: 1326 | epoch: 38 | time_per_epoch: 12.908297538757324 | train_acc: 0.6083446284400966 | avg_loss_per_ep: 1.827567963039174
Step: 1340 | epoch: 39 | loss: 1.8217968940734863 | lr: 0.0008786999220643853
Step: 1360 | epoch: 39 | time_per_epoch: 12.568479299545288 | train_acc: 0.6081678354646709 | avg_loss_per_ep: 1.8227590077063616
Step: 1360 | epoch: 40 | loss: 1.8277785778045654 | lr: 0.0008740208763086188
Step: 1380 | epoch: 40 | loss: 1.7438318729400635 | lr: 0.000869266252113065
Step: 1394 | epoch: 40 | time_per_epoch: 13.546331882476807 | train_acc: 0.6223112734987329 | avg_loss_per_ep: 1.790715200059554
Step: 1394 | epoch: 40 | val_loss: 1.3463257074356079 | val_acc: 0.7992185151788398
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.7992185151788398.
Step: 1400 | epoch: 41 | loss: 1.7679388523101807 | lr: 0.000864437010258004
Step: 1420 | epoch: 41 | loss: 1.7898166179656982 | lr: 0.0008595341266019171
Step: 1428 | epoch: 41 | time_per_epoch: 18.406620025634766 | train_acc: 0.6267310978843774 | avg_loss_per_ep: 1.76928390825496
Step: 1440 | epoch: 42 | loss: 1.8333303928375244 | lr: 0.0008545585918842907
Step: 1460 | epoch: 42 | loss: 1.8266594409942627 | lr: 0.0008495114115254147
Step: 1462 | epoch: 42 | time_per_epoch: 7.181016683578491 | train_acc: 0.63415640285226 | avg_loss_per_ep: 1.7451723673764397
Step: 1480 | epoch: 43 | loss: 1.7287977933883667 | lr: 0.0008443936054232166
Step: 1496 | epoch: 43 | time_per_epoch: 13.65507984161377 | train_acc: 0.632565266073428 | avg_loss_per_ep: 1.743795717463774
Step: 1500 | epoch: 44 | loss: 1.731029748916626 | lr: 0.000839206207747165
Step: 1520 | epoch: 44 | loss: 1.7133967876434326 | lr: 0.0008339502667292945
Step: 1530 | epoch: 44 | time_per_epoch: 13.313397407531738 | train_acc: 0.6340974718604514 | avg_loss_per_ep: 1.7500672270269955
Step: 1540 | epoch: 45 | loss: 1.6012775897979736 | lr: 0.0008286268444523857
Step: 1560 | epoch: 45 | loss: 1.7672550678253174 | lr: 0.0008232370166353458
Step: 1564 | epoch: 45 | time_per_epoch: 14.280263900756836 | train_acc: 0.6443514644351465 | avg_loss_per_ep: 1.7162531649365145
Step: 1564 | epoch: 45 | val_loss: 1.3003524780273437 | val_acc: 0.8087365995391244
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8087365995391244.
Step: 1580 | epoch: 46 | loss: 1.7374417781829834 | lr: 0.0008177818724158376
Step: 1598 | epoch: 46 | time_per_epoch: 13.702910661697388 | train_acc: 0.6409923979020566 | avg_loss_per_ep: 1.7174489989000208
Step: 1600 | epoch: 47 | loss: 1.7765719890594482 | lr: 0.0008122625141301913
Step: 1620 | epoch: 47 | loss: 1.642991542816162 | lr: 0.0008066800570906559
Step: 1632 | epoch: 47 | time_per_epoch: 14.768743753433228 | train_acc: 0.6487123578289823 | avg_loss_per_ep: 1.7175632259424995
Step: 1640 | epoch: 48 | loss: 1.6647546291351318 | lr: 0.0008010356293600221
Step: 1660 | epoch: 48 | loss: 1.6223058700561523 | lr: 0.0007953303715236726
Step: 1666 | epoch: 48 | time_per_epoch: 19.792816162109375 | train_acc: 0.6541929400671813 | avg_loss_per_ep: 1.6848189024364246
Step: 1680 | epoch: 49 | loss: 1.6827152967453003 | lr: 0.0007895654364590993
Step: 1700 | epoch: 49 | time_per_epoch: 12.136009931564331 | train_acc: 0.6594967293299546 | avg_loss_per_ep: 1.6833241055993473
Step: 1700 | epoch: 50 | loss: 1.6338169574737549 | lr: 0.000783741989102942
Step: 1720 | epoch: 50 | loss: 1.6158838272094727 | lr: 0.0007778612062155815
Step: 1734 | epoch: 50 | time_per_epoch: 11.799763202667236 | train_acc: 0.6637397607401733 | avg_loss_per_ep: 1.6643926781766556
Step: 1734 | epoch: 50 | val_loss: 1.2755606174468994 | val_acc: 0.8148482116020439
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8148482116020439.
Step: 1740 | epoch: 51 | loss: 1.7039363384246826 | lr: 0.0007719242761433516
Step: 1760 | epoch: 51 | loss: 1.6725475788116455 | lr: 0.0007659323985784055
Step: 1768 | epoch: 51 | time_per_epoch: 12.460896015167236 | train_acc: 0.6656255524780482 | avg_loss_per_ep: 1.6581451682483448
Step: 1780 | epoch: 52 | loss: 1.576285481452942 | lr: 0.0007598867843162907
Step: 1800 | epoch: 52 | loss: 1.6201772689819336 | lr: 0.0007537886550112802
Step: 1802 | epoch: 52 | time_per_epoch: 11.725354433059692 | train_acc: 0.6683363781012435 | avg_loss_per_ep: 1.652580639895271
Step: 1820 | epoch: 53 | loss: 1.6534616947174072 | lr: 0.0007476392429295091
Step: 1836 | epoch: 53 | time_per_epoch: 16.41896080970764 | train_acc: 0.6594377983381461 | avg_loss_per_ep: 1.6731518892680897
Step: 1840 | epoch: 54 | loss: 1.6812148094177246 | lr: 0.0007414397906999683
Step: 1860 | epoch: 54 | loss: 1.6893951892852783 | lr: 0.0007351915510634011
Step: 1870 | epoch: 54 | time_per_epoch: 11.364901542663574 | train_acc: 0.6574930756084625 | avg_loss_per_ep: 1.6844173003645504
Step: 1880 | epoch: 55 | loss: 1.6655681133270264 | lr: 0.00072889578661916
Step: 1900 | epoch: 55 | loss: 1.562633752822876 | lr: 0.0007225537695700683
Step: 1904 | epoch: 55 | time_per_epoch: 17.022338390350342 | train_acc: 0.6676881371913489 | avg_loss_per_ep: 1.6543818922603832
Step: 1904 | epoch: 55 | val_loss: 1.2646258115768432 | val_acc: 0.8233643923454563
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8233643923454563.
Step: 1920 | epoch: 56 | loss: 1.582301139831543 | lr: 0.0007161667814653434
Step: 1938 | epoch: 56 | time_per_epoch: 9.188011169433594 | train_acc: 0.6769992338971065 | avg_loss_per_ep: 1.6267358695759493
Step: 1940 | epoch: 57 | loss: 1.7051670551300049 | lr: 0.0007097361129416311
Step: 1960 | epoch: 57 | loss: 1.5716536045074463 | lr: 0.0007032630634622012
Step: 1972 | epoch: 57 | time_per_epoch: 19.0527126789093 | train_acc: 0.6757616830691261 | avg_loss_per_ep: 1.6345189459183638
Step: 1980 | epoch: 58 | loss: 1.6339380741119385 | lr: 0.0006967489410543632
Step: 2000 | epoch: 58 | loss: 1.659745693206787 | lr: 0.0006901950620451484
Step: 2006 | epoch: 58 | time_per_epoch: 9.747060060501099 | train_acc: 0.6738758913312511 | avg_loss_per_ep: 1.6313607377164505
Step: 2020 | epoch: 59 | loss: 1.5924876928329468 | lr: 0.0006836027507953168
Step: 2040 | epoch: 59 | time_per_epoch: 18.53326392173767 | train_acc: 0.6797689905121104 | avg_loss_per_ep: 1.612025096135981
Step: 2040 | epoch: 60 | loss: 1.5513007640838623 | lr: 0.0006769733394317391
Step: 2060 | epoch: 60 | loss: 1.6020910739898682 | lr: 0.0006703081675782092
Step: 2074 | epoch: 60 | time_per_epoch: 16.927289485931396 | train_acc: 0.687901467381696 | avg_loss_per_ep: 1.5997709842289196
Step: 2074 | epoch: 60 | val_loss: 1.231945538520813 | val_acc: 0.8327822863440537
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8327822863440537.
Step: 2080 | epoch: 61 | loss: 1.5913231372833252 | lr: 0.0006636085820847453
Step: 2100 | epoch: 61 | loss: 1.6472370624542236 | lr: 0.0006568759367554257
Step: 2108 | epoch: 61 | time_per_epoch: 11.943761825561523 | train_acc: 0.6852495727503094 | avg_loss_per_ep: 1.6041669530027054
Step: 2120 | epoch: 62 | loss: 1.5849425792694092 | lr: 0.0006501115920748232
Step: 2140 | epoch: 62 | loss: 1.6132795810699463 | lr: 0.0006433169149330871
Step: 2142 | epoch: 62 | time_per_epoch: 15.896216869354248 | train_acc: 0.6904944310212741 | avg_loss_per_ep: 1.5882749662679785
Step: 2160 | epoch: 63 | loss: 1.5737273693084717 | lr: 0.0006364932783497331
Step: 2176 | epoch: 63 | time_per_epoch: 18.517154932022095 | train_acc: 0.6985090459072426 | avg_loss_per_ep: 1.5674934106714584
Step: 2180 | epoch: 64 | loss: 1.532142162322998 | lr: 0.0006296420611961919
Step: 2200 | epoch: 64 | loss: 1.5760459899902344 | lr: 0.0006227646479171783
Step: 2210 | epoch: 64 | time_per_epoch: 11.79567575454712 | train_acc: 0.6959750132594732 | avg_loss_per_ep: 1.5587295995039099
Step: 2220 | epoch: 65 | loss: 1.6188602447509766 | lr: 0.0006158624282509313
Step: 2240 | epoch: 65 | loss: 1.660153865814209 | lr: 0.0006089367969483866
Step: 2244 | epoch: 65 | time_per_epoch: 16.373952388763428 | train_acc: 0.693264187636278 | avg_loss_per_ep: 1.581312070874607
Step: 2244 | epoch: 65 | val_loss: 1.2196995139122009 | val_acc: 0.8355876164712954
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8355876164712954.
Step: 2260 | epoch: 66 | loss: 1.559843897819519 | lr: 0.0006019891534913348
Step: 2278 | epoch: 66 | time_per_epoch: 11.619449615478516 | train_acc: 0.6937356355707467 | avg_loss_per_ep: 1.56750869400361
Step: 2280 | epoch: 67 | loss: 1.621978521347046 | lr: 0.0005950209018096251
Step: 2300 | epoch: 67 | loss: 1.5111534595489502 | lr: 0.0005880334499974677
Step: 2312 | epoch: 67 | time_per_epoch: 24.213826894760132 | train_acc: 0.6978018740055395 | avg_loss_per_ep: 1.5661456514807308
Step: 2320 | epoch: 68 | loss: 1.5977230072021484 | lr: 0.0005810282100288983
Step: 2340 | epoch: 68 | loss: 1.5705509185791016 | lr: 0.000574006597472454
Step: 2346 | epoch: 68 | time_per_epoch: 9.733896255493164 | train_acc: 0.7009841475632035 | avg_loss_per_ep: 1.5506138100343592
Step: 2360 | epoch: 69 | loss: 1.6087563037872314 | lr: 0.000566970031205128
Step: 2380 | epoch: 69 | time_per_epoch: 12.00459337234497 | train_acc: 0.7017502504567152 | avg_loss_per_ep: 1.5605347156524658
Step: 2380 | epoch: 70 | loss: 1.5758236646652222 | lr: 0.0005599199331256506
Step: 2400 | epoch: 70 | loss: 1.564342737197876 | lr: 0.0005528577278671649
Step: 2414 | epoch: 70 | time_per_epoch: 16.0937442779541 | train_acc: 0.7084683835228947 | avg_loss_per_ep: 1.5344892845434301
Step: 2414 | epoch: 70 | val_loss: 1.2008711993694305 | val_acc: 0.8431018935978359
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8431018935978359.
Step: 2420 | epoch: 71 | loss: 1.5037431716918945 | lr: 0.0005457848425093444
Step: 2440 | epoch: 71 | loss: 1.546462059020996 | lr: 0.0005387027062900212
Step: 2448 | epoch: 71 | time_per_epoch: 11.942250728607178 | train_acc: 0.7135953798102422 | avg_loss_per_ep: 1.5186265110969543
Step: 2460 | epoch: 72 | loss: 1.450061559677124 | lr: 0.0005316127503163752
Step: 2480 | epoch: 72 | loss: 1.4982675313949585 | lr: 0.0005245164072757452
Step: 2482 | epoch: 72 | time_per_epoch: 11.786000967025757 | train_acc: 0.7140078967529023 | avg_loss_per_ep: 1.5178870734046488
Step: 2500 | epoch: 73 | loss: 1.5800623893737793 | lr: 0.0005174151111461224
Step: 2516 | epoch: 73 | time_per_epoch: 20.70334506034851 | train_acc: 0.7165419294006719 | avg_loss_per_ep: 1.5080847109065336
Step: 2520 | epoch: 74 | loss: 1.563401222229004 | lr: 0.0005103102969063834
Step: 2540 | epoch: 74 | loss: 1.4737706184387207 | lr: 0.0005032034002463195
Step: 2550 | epoch: 74 | time_per_epoch: 13.921197414398193 | train_acc: 0.7207260298190818 | avg_loss_per_ep: 1.5014882648692411
Step: 2560 | epoch: 75 | loss: 1.4902734756469727 | lr: 0.0004960958572765211
Step: 2580 | epoch: 75 | loss: 1.4951326847076416 | lr: 0.0004889891042381819
Step: 2584 | epoch: 75 | time_per_epoch: 14.108767986297607 | train_acc: 0.7204903058518475 | avg_loss_per_ep: 1.4992160271195805
Step: 2584 | epoch: 75 | val_loss: 1.1758918821811677 | val_acc: 0.8494138863841298
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8494138863841298.
Step: 2600 | epoch: 76 | loss: 1.4445216655731201 | lr: 0.00048188457721287073
Step: 2618 | epoch: 76 | time_per_epoch: 17.37030577659607 | train_acc: 0.7186045141139725 | avg_loss_per_ep: 1.5015263347064747
Step: 2620 | epoch: 77 | loss: 1.4684109687805176 | lr: 0.00047478371183234036
Step: 2640 | epoch: 77 | loss: 1.5976476669311523 | lr: 0.0004676879429884242
Step: 2652 | epoch: 77 | time_per_epoch: 14.090219736099243 | train_acc: 0.7257940951146208 | avg_loss_per_ep: 1.491129219532013
Step: 2660 | epoch: 78 | loss: 1.4835963249206543 | lr: 0.00046059870454308473
Step: 2680 | epoch: 78 | loss: 1.4661738872528076 | lr: 0.0004535174290386678
Step: 2686 | epoch: 78 | time_per_epoch: 9.385505437850952 | train_acc: 0.7233189934586599 | avg_loss_per_ep: 1.489803755984587
Step: 2700 | epoch: 79 | loss: 1.4979044198989868 | lr: 0.00044644554740842606
Step: 2720 | epoch: 79 | time_per_epoch: 16.836493253707886 | train_acc: 0.7264423360245152 | avg_loss_per_ep: 1.4921021741979263
Step: 2720 | epoch: 80 | loss: 1.5589141845703125 | lr: 0.0004393844886873649
Step: 2740 | epoch: 80 | loss: 1.4563729763031006 | lr: 0.00043233567972347434
Step: 2754 | epoch: 80 | time_per_epoch: 14.499527215957642 | train_acc: 0.7305085744593082 | avg_loss_per_ep: 1.4645308606764849
Step: 2754 | epoch: 80 | val_loss: 1.1726537764072418 | val_acc: 0.8513175032561867
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8513175032561867.
Step: 2760 | epoch: 81 | loss: 1.506087064743042 | lr: 0.0004253005448894019
Step: 2780 | epoch: 81 | loss: 1.466882348060608 | lr: 0.00041828050579462465
Step: 2788 | epoch: 81 | time_per_epoch: 16.398295164108276 | train_acc: 0.7292120926395191 | avg_loss_per_ep: 1.4667551868102129
Step: 2800 | epoch: 82 | loss: 1.5391945838928223 | lr: 0.00041127698099818164
Step: 2820 | epoch: 82 | loss: 1.4764641523361206 | lr: 0.0004042913857220211
Step: 2822 | epoch: 82 | time_per_epoch: 18.496996641159058 | train_acc: 0.7293888856149449 | avg_loss_per_ep: 1.4605664190124064
Step: 2840 | epoch: 83 | loss: 1.433322787284851 | lr: 0.00039732513156502235
Step: 2856 | epoch: 83 | time_per_epoch: 11.889646291732788 | train_acc: 0.7298603335494136 | avg_loss_per_ep: 1.4699547255740446
Step: 2860 | epoch: 84 | loss: 1.467198133468628 | lr: 0.00039037962621775023
Step: 2880 | epoch: 84 | loss: 1.443415641784668 | lr: 0.00038345627317800036
Step: 2890 | epoch: 84 | time_per_epoch: 9.829625368118286 | train_acc: 0.7353409157876127 | avg_loss_per_ep: 1.4546194286907421
Step: 2900 | epoch: 85 | loss: 1.4270024299621582 | lr: 0.0003765564714671883
Step: 2920 | epoch: 85 | loss: 1.3979339599609375 | lr: 0.00036968161534764693
Step: 2924 | epoch: 85 | time_per_epoch: 9.772199869155884 | train_acc: 0.7381106724026165 | avg_loss_per_ep: 1.4504168910138748
Step: 2924 | epoch: 85 | val_loss: 1.1566782772541047 | val_acc: 0.8557258791704238
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8557258791704238.
Step: 2940 | epoch: 86 | loss: 1.4719115495681763 | lr: 0.0003628330940408825
Step: 2958 | epoch: 86 | time_per_epoch: 7.302104949951172 | train_acc: 0.74382697860805 | avg_loss_per_ep: 1.4326398968696594
Step: 2960 | epoch: 87 | loss: 1.4996373653411865 | lr: 0.0003560122914468524
Step: 2980 | epoch: 87 | loss: 1.4452353715896606 | lr: 0.00034922058586431563
Step: 2992 | epoch: 87 | time_per_epoch: 9.86215877532959 | train_acc: 0.7431198067063469 | avg_loss_per_ep: 1.4321228931931889
Step: 3000 | epoch: 88 | loss: 1.4090783596038818 | lr: 0.0003424593497123158
Step: 3020 | epoch: 88 | loss: 1.3989896774291992 | lr: 0.00033572994925285384
Step: 3026 | epoch: 88 | time_per_epoch: 9.869409322738647 | train_acc: 0.7483057339855029 | avg_loss_per_ep: 1.421740759821499
Step: 3040 | epoch: 89 | loss: 1.4182140827178955 | lr: 0.00032903374431480234
Step: 3060 | epoch: 89 | time_per_epoch: 9.361405849456787 | train_acc: 0.7454770463786905 | avg_loss_per_ep: 1.419634966289296
Step: 3060 | epoch: 90 | loss: 1.3731533288955688 | lr: 0.000322372088019121
Step: 3080 | epoch: 90 | loss: 1.4530905485153198 | lr: 0.00031574632650542946
Step: 3094 | epoch: 90 | time_per_epoch: 15.797798156738281 | train_acc: 0.7463020802640108 | avg_loss_per_ep: 1.4190122800714828
Step: 3094 | epoch: 90 | val_loss: 1.1459728062152863 | val_acc: 0.8602344454463481
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8602344454463481.
Step: 3100 | epoch: 91 | loss: 1.4147202968597412 | lr: 0.00030915779865998673
Step: 3120 | epoch: 91 | loss: 1.4139233827590942 | lr: 0.00030260783584514
Step: 3128 | epoch: 91 | time_per_epoch: 13.075188159942627 | train_acc: 0.7475985620837998 | avg_loss_per_ep: 1.4204835470984964
Step: 3140 | epoch: 92 | loss: 1.3394322395324707 | lr: 0.00029609776163029306
Step: 3160 | epoch: 92 | loss: 1.455424189567566 | lr: 0.00028962889152444666
Step: 3162 | epoch: 92 | time_per_epoch: 20.271152019500732 | train_acc: 0.752489834403913 | avg_loss_per_ep: 1.4074664782075321
Step: 3180 | epoch: 93 | loss: 1.4413570165634155 | lr: 0.000283202532710373
Step: 3196 | epoch: 93 | time_per_epoch: 12.057223558425903 | train_acc: 0.7556131769697684 | avg_loss_per_ep: 1.3970177243737614
Step: 3200 | epoch: 94 | loss: 1.3750327825546265 | lr: 0.00027681998378046695
Step: 3220 | epoch: 94 | loss: 1.3488411903381348 | lr: 0.0002704825344743372
Step: 3230 | epoch: 94 | time_per_epoch: 12.891332387924194 | train_acc: 0.7578525546584949 | avg_loss_per_ep: 1.391664420857149
Step: 3240 | epoch: 95 | loss: 1.4057643413543701 | lr: 0.000264191465418185
Step: 3260 | epoch: 95 | loss: 1.3890082836151123 | lr: 0.0002579480478660235
Step: 3264 | epoch: 95 | time_per_epoch: 10.529118537902832 | train_acc: 0.7552006600271083 | avg_loss_per_ep: 1.3969098364605623
Step: 3264 | epoch: 95 | val_loss: 1.1467197716236115 | val_acc: 0.8606352068930969
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8606352068930969.
Step: 3280 | epoch: 96 | loss: 1.2841129302978516 | lr: 0.00025175354344279257
Step: 3298 | epoch: 96 | time_per_epoch: 12.980849981307983 | train_acc: 0.7565560728387059 | avg_loss_per_ep: 1.3973684381036198
Step: 3300 | epoch: 97 | loss: 1.3064368963241577 | lr: 0.00024560920388941917
Step: 3320 | epoch: 97 | loss: 1.329469084739685 | lr: 0.00023951627080987306
Step: 3332 | epoch: 97 | time_per_epoch: 12.962861061096191 | train_acc: 0.765218928634569 | avg_loss_per_ep: 1.378131158211652
Step: 3340 | epoch: 98 | loss: 1.3890671730041504 | lr: 0.00023347597542027417
Step: 3360 | epoch: 98 | loss: 1.3751389980316162 | lr: 0.00022748953830009579
Step: 3366 | epoch: 98 | time_per_epoch: 10.448430061340332 | train_acc: 0.7544934881254052 | avg_loss_per_ep: 1.3983732461929321
Step: 3380 | epoch: 99 | loss: 1.3613340854644775 | lr: 0.00022155816914551921
Step: 3400 | epoch: 99 | time_per_epoch: 12.924391984939575 | train_acc: 0.76433496375744 | avg_loss_per_ep: 1.3712411803357742
Step: 3400 | epoch: 100 | loss: 1.4338678121566772 | lr: 0.00021568306652498787
Step: 3420 | epoch: 100 | loss: 1.395129680633545 | lr: 0.00020986541763700768
Step: 3434 | epoch: 100 | time_per_epoch: 10.380779504776001 | train_acc: 0.7641581707820143 | avg_loss_per_ep: 1.3749118096688215
Step: 3434 | epoch: 100 | val_loss: 1.1362162172794341 | val_acc: 0.8628393948502154
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8628393948502154.
Step: 3440 | epoch: 101 | loss: 1.3295483589172363 | lr: 0.00020410639807024714
Step: 3460 | epoch: 101 | loss: 1.3190319538116455 | lr: 0.00019840717156598394
Step: 3468 | epoch: 101 | time_per_epoch: 12.89195990562439 | train_acc: 0.759856208379987 | avg_loss_per_ep: 1.385329569087309
Step: 3480 | epoch: 102 | loss: 1.3102456331253052 | lr: 0.00019276888978294248
Step: 3500 | epoch: 102 | loss: 1.3339507579803467 | lr: 0.0001871926920645763
Step: 3502 | epoch: 102 | time_per_epoch: 10.37243103981018 | train_acc: 0.7638635158229713 | avg_loss_per_ep: 1.3753043413162231
Step: 3520 | epoch: 103 | loss: 1.3423935174942017 | lr: 0.00018167970520883782
Step: 3536 | epoch: 103 | time_per_epoch: 12.924619674682617 | train_acc: 0.7658082385526549 | avg_loss_per_ep: 1.3663297435816597
Step: 3540 | epoch: 104 | loss: 1.2950348854064941 | lr: 0.00017623104324048208
Step: 3560 | epoch: 104 | loss: 1.3261566162109375 | lr: 0.000170847807185954
Step: 3570 | epoch: 104 | time_per_epoch: 12.901626825332642 | train_acc: 0.770699510872768 | avg_loss_per_ep: 1.363413228708155
Step: 3580 | epoch: 105 | loss: 1.4275789260864258 | lr: 0.0001655310848508995
Step: 3600 | epoch: 105 | loss: 1.3433799743652344 | lr: 0.00016028195060035022
Step: 3604 | epoch: 105 | time_per_epoch: 10.40856385231018 | train_acc: 0.7645706877246744 | avg_loss_per_ep: 1.3705003331689274
Step: 3604 | epoch: 105 | val_loss: 1.1364747881889343 | val_acc: 0.8629395852119026
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8629395852119026.
Step: 3620 | epoch: 106 | loss: 1.364364743232727 | lr: 0.00015510146514162397
Step: 3638 | epoch: 106 | time_per_epoch: 12.965028285980225 | train_acc: 0.7718191997171312 | avg_loss_per_ep: 1.356335412053501
Step: 3640 | epoch: 107 | loss: 1.2552191019058228 | lr: 0.00014999067530998384
Step: 3660 | epoch: 107 | loss: 1.3042364120483398 | lr: 0.00014495061385710138
Step: 3672 | epoch: 107 | time_per_epoch: 10.392658948898315 | train_acc: 0.7724085096352171 | avg_loss_per_ep: 1.3462057569447685
Step: 3680 | epoch: 108 | loss: 1.401817798614502 | lr: 0.0001399822992423663
Step: 3700 | epoch: 108 | loss: 1.3755407333374023 | lr: 0.0001350867354270825
Step: 3706 | epoch: 108 | time_per_epoch: 12.939888954162598 | train_acc: 0.7687547881430844 | avg_loss_per_ep: 1.3618262164732988
Step: 3720 | epoch: 109 | loss: 1.3468897342681885 | lr: 0.00013026491167159566
Step: 3740 | epoch: 109 | time_per_epoch: 12.993431091308594 | train_acc: 0.7710530968236196 | avg_loss_per_ep: 1.3572378018323112
Step: 3740 | epoch: 110 | loss: 1.3654154539108276 | lr: 0.00012551780233539003
Step: 3760 | epoch: 110 | loss: 1.2770295143127441 | lr: 0.000120846366680197
Step: 3774 | epoch: 110 | time_per_epoch: 10.560497522354126 | train_acc: 0.7710530968236196 | avg_loss_per_ep: 1.3495414046680225
Step: 3774 | epoch: 110 | val_loss: 1.1284628570079804 | val_acc: 0.8642420599138363
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8642420599138363.
Step: 3780 | epoch: 111 | loss: 1.3836393356323242 | lr: 0.00011625154867615472
Step: 3800 | epoch: 111 | loss: 1.2611254453659058 | lr: 0.00011173427681105696
Step: 3808 | epoch: 111 | time_per_epoch: 12.963799953460693 | train_acc: 0.776180093110967 | avg_loss_per_ep: 1.3532671086928423
Step: 3820 | epoch: 112 | loss: 1.3072295188903809 | lr: 0.00010729546390273094
Step: 3840 | epoch: 112 | loss: 1.3933353424072266 | lr: 0.00010293600691458241
Step: 3842 | epoch: 112 | time_per_epoch: 10.500689029693604 | train_acc: 0.7737049914550062 | avg_loss_per_ep: 1.3466986312585718
Step: 3860 | epoch: 113 | loss: 1.3188046216964722 | lr: 9.865678677434276e-05
Step: 3876 | epoch: 113 | time_per_epoch: 12.970390796661377 | train_acc: 0.7758854381519241 | avg_loss_per_ep: 1.344915947493385
Step: 3880 | epoch: 114 | loss: 1.2881731986999512 | lr: 9.4458668196058e-05
Step: 3900 | epoch: 114 | loss: 1.323840856552124 | lr: 9.034249950535373e-05
Step: 3910 | epoch: 114 | time_per_epoch: 10.472827911376953 | train_acc: 0.7801284695621428 | avg_loss_per_ep: 1.3342882114298202
Step: 3920 | epoch: 115 | loss: 1.3621711730957031 | lr: 8.630911246801071e-05
Step: 3940 | epoch: 115 | loss: 1.3459869623184204 | lr: 8.235932212188905e-05
Step: 3944 | epoch: 115 | time_per_epoch: 13.030392169952393 | train_acc: 0.7805999174966115 | avg_loss_per_ep: 1.33415104711757
Step: 3944 | epoch: 115 | val_loss: 1.1276917934417725 | val_acc: 0.8664462478709548
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8664462478709548.
Step: 3960 | epoch: 116 | loss: 1.4149478673934937 | lr: 7.849392661222991e-05
Step: 3978 | epoch: 116 | time_per_epoch: 12.935307502746582 | train_acc: 0.7762390241027757 | avg_loss_per_ep: 1.3422432752216564
Step: 3980 | epoch: 117 | loss: 1.3531970977783203 | lr: 7.47137070303725e-05
Step: 4000 | epoch: 117 | loss: 1.2708768844604492 | lr: 7.10194272559172e-05
Step: 4012 | epoch: 117 | time_per_epoch: 10.442800998687744 | train_acc: 0.7807177794802287 | avg_loss_per_ep: 1.326318968744839
Step: 4020 | epoch: 118 | loss: 1.2938463687896729 | lr: 6.741183380236543e-05
Step: 4040 | epoch: 118 | loss: 1.3212676048278809 | lr: 6.389165566627023e-05
Step: 4046 | epoch: 118 | time_per_epoch: 13.446948528289795 | train_acc: 0.7822499852672521 | avg_loss_per_ep: 1.3256034710827995
Step: 4060 | epoch: 119 | loss: 1.3164854049682617 | lr: 6.045960417992568e-05
Step: 4080 | epoch: 119 | time_per_epoch: 10.941394805908203 | train_acc: 0.7831339501443809 | avg_loss_per_ep: 1.3336426615715027
Step: 4080 | epoch: 120 | loss: 1.390963077545166 | lr: 5.711637286762581e-05
Step: 4100 | epoch: 120 | loss: 1.30607008934021 | lr: 5.386263730552224e-05
Step: 4114 | epoch: 120 | time_per_epoch: 13.020219087600708 | train_acc: 0.7780069538570334 | avg_loss_per_ep: 1.3356532349305994
Step: 4114 | epoch: 120 | val_loss: 1.1216079413890838 | val_acc: 0.8681494840196373
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.8681494840196373.
Step: 4120 | epoch: 121 | loss: 1.3255549669265747 | lr: 5.069905498510919e-05
Step: 4140 | epoch: 121 | loss: 1.363111972808838 | lr: 4.762626518036121e-05
Step: 4148 | epoch: 121 | time_per_epoch: 10.45743441581726 | train_acc: 0.7821910542754434 | avg_loss_per_ep: 1.3321308002752417
Step: 4160 | epoch: 122 | loss: 1.3144739866256714 | lr: 4.464488881855444e-05
Step: 4180 | epoch: 122 | loss: 1.2341153621673584 | lr: 4.175552835479327e-05
Step: 4182 | epoch: 122 | time_per_epoch: 13.052824258804321 | train_acc: 0.7846072249395958 | avg_loss_per_ep: 1.3284680387553047
Step: 4200 | epoch: 123 | loss: 1.26214599609375 | lr: 3.895876765027082e-05
Step: 4216 | epoch: 123 | time_per_epoch: 13.049498796463013 | train_acc: 0.7850786728740645 | avg_loss_per_ep: 1.3179040410939384
Step: 4220 | epoch: 124 | loss: 1.3251488208770752 | lr: 3.6255171854286746e-05
Step: 4240 | epoch: 124 | loss: 1.33935546875 | lr: 3.364528729004543e-05
Step: 4250 | epoch: 124 | time_per_epoch: 10.60195279121399 | train_acc: 0.784135777005127 | avg_loss_per_ep: 1.324538059094373
Step: 4260 | epoch: 125 | loss: 1.3038995265960693 | lr: 3.1129641344259214e-05
Step: 4280 | epoch: 125 | loss: 1.3587136268615723 | lr: 2.8708742360577968e-05
Step: 4284 | epoch: 125 | time_per_epoch: 13.389800071716309 | train_acc: 0.7851376038658731 | avg_loss_per_ep: 1.3191089770373177
Step: 4284 | epoch: 125 | val_loss: 1.1217733502388 | val_acc: 0.8668470093177036
Step: 4300 | epoch: 126 | loss: 1.353748083114624 | lr: 2.6383079536866247e-05
Step: 4318 | epoch: 126 | time_per_epoch: 10.811599493026733 | train_acc: 0.7853143968412989 | avg_loss_per_ep: 1.3182883087326498
Step: 4320 | epoch: 127 | loss: 1.2891395092010498 | lr: 2.4153122826350335e-05
Step: 4340 | epoch: 127 | loss: 1.2763863801956177 | lr: 2.2019322842652884e-05
Step: 4352 | epoch: 127 | time_per_epoch: 13.395406007766724 | train_acc: 0.782544640226295 | avg_loss_per_ep: 1.319245629450854
Step: 4360 | epoch: 128 | loss: 1.3641443252563477 | lr: 1.998211076873621e-05
Step: 4380 | epoch: 128 | loss: 1.2819714546203613 | lr: 1.8041898269772542e-05
Step: 4386 | epoch: 128 | time_per_epoch: 13.235976696014404 | train_acc: 0.7831339501443809 | avg_loss_per_ep: 1.3228770950261284
Step: 4400 | epoch: 129 | loss: 1.2314852476119995 | lr: 1.6199077409957003e-05
Step: 4420 | epoch: 129 | time_per_epoch: 10.619708776473999 | train_acc: 0.7874359125464081 | avg_loss_per_ep: 1.3079225350828732
Step: 4420 | epoch: 130 | loss: 1.3841462135314941 | lr: 1.4454020573282306e-05
Step: 4440 | epoch: 130 | loss: 1.3103445768356323 | lr: 1.2807080388290278e-05
Step: 4454 | epoch: 130 | time_per_epoch: 13.312146663665771 | train_acc: 0.7833696741116153 | avg_loss_per_ep: 1.3249310535543106
Step: 4454 | epoch: 130 | val_loss: 1.1208668768405914 | val_acc: 0.869451958721571
Saved ./runs/kwt1_finetune_mean/best.pth with accuracy 0.869451958721571.
Step: 4460 | epoch: 131 | loss: 1.3723342418670654 | lr: 1.1258589656814898e-05
Step: 4480 | epoch: 131 | loss: 1.2734917402267456 | lr: 9.808861286732316e-06
Step: 4488 | epoch: 131 | time_per_epoch: 10.753670692443848 | train_acc: 0.7887913253580058 | avg_loss_per_ep: 1.3141240021761726
Step: 4500 | epoch: 132 | loss: 1.3004422187805176 | lr: 8.458188228730748e-06
Step: 4520 | epoch: 132 | loss: 1.2634193897247314 | lr: 7.206843417112672e-06
Step: 4522 | epoch: 132 | time_per_epoch: 13.261482238769531 | train_acc: 0.7851376038658731 | avg_loss_per_ep: 1.314095998511595
Step: 4540 | epoch: 133 | loss: 1.3548800945281982 | lr: 6.055079714642861e-06
Step: 4556 | epoch: 133 | time_per_epoch: 10.532164096832275 | train_acc: 0.7843715009723614 | avg_loss_per_ep: 1.3222373969414656
Step: 4560 | epoch: 134 | loss: 1.2829416990280151 | lr: 5.003129861451128e-06
Step: 4580 | epoch: 134 | loss: 1.3244190216064453 | lr: 4.0512064280021645e-06
Step: 4590 | epoch: 134 | time_per_epoch: 13.019783973693848 | train_acc: 0.7865519476692793 | avg_loss_per_ep: 1.3205379773588741
Step: 4600 | epoch: 135 | loss: 1.2881393432617188 | lr: 3.199501772140814e-06
Step: 4620 | epoch: 135 | loss: 1.4044969081878662 | lr: 2.4481880002217246e-06
Step: 4624 | epoch: 135 | time_per_epoch: 13.003475666046143 | train_acc: 0.7830160881607637 | avg_loss_per_ep: 1.3279188029906328
Step: 4624 | epoch: 135 | val_loss: 1.1207556426525116 | val_acc: 0.8688508165514478
Step: 4640 | epoch: 136 | loss: 1.2783803939819336 | lr: 1.7974169323312976e-06
Step: 4658 | epoch: 136 | time_per_epoch: 10.69330096244812 | train_acc: 0.7884966703989628 | avg_loss_per_ep: 1.3094799273154314
Step: 4660 | epoch: 137 | loss: 1.252838373184204 | lr: 1.2473200716090887e-06
Step: 4680 | epoch: 137 | loss: 1.3012614250183105 | lr: 7.980085776745512e-07
Step: 4692 | epoch: 137 | time_per_epoch: 13.172632455825806 | train_acc: 0.7840179150215099 | avg_loss_per_ep: 1.314514665042653
Step: 4700 | epoch: 138 | loss: 1.3325235843658447 | lr: 4.495732441645084e-07
Step: 4720 | epoch: 138 | loss: 1.4130582809448242 | lr: 2.0208448038662413e-07
Step: 4726 | epoch: 138 | time_per_epoch: 10.750716924667358 | train_acc: 0.7830160881607637 | avg_loss_per_ep: 1.3224055977428661
Step: 4740 | epoch: 139 | loss: 1.3381109237670898 | lr: 5.5592297091313796e-08
Step: 4760 | epoch: 139 | time_per_epoch: 13.104635000228882 | train_acc: 0.7788319877423537 | avg_loss_per_ep: 1.3324102724299711
Step: 4760 | epoch: 139 | val_loss: 1.1204024314880372 | val_acc: 0.8692515779981965
Saved ./runs/kwt1_finetune_mean/last.pth with accuracy 0.8692515779981965.
Step: 4794 | test_loss_last: 1.1756447662006726 | test_acc_last: 0.84379827351204
Step: 4794 | test_loss_best: 1.175783802162517 | test_acc_best: 0.8439800090867787
